---
title: "W203: Lab 3"
author: "Deepak Nagaraj"
date: "3/19/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, tidy.opts=list(width.cutoff=80), tidy=TRUE)
```

```{r setup, echo=FALSE}
library(sqldf)
library(ggplot2)
library(gridExtra)
library(stargazer)
library(car)
library(dplyr)
```

## About the dataset:
* A selection of counties in North Carolina
* Original: Cornwell and Trumball (1994)

## What to do:
* Understand determinants of crime
* Generate policy suggestions applicable to local government
* Provide research for a political campaign

## What to do for Week 1:
* Identify variables of interest
* Any transformations for each variable?
* Support from EDA?
* What covariates can identify causal effect?  Which ones are problematic (multicollinearity or dampening)
* Produce 3 models:
    - One model with only explanatory variables of key interest (and no covariates)
    - Above, plus covariates that increase accuracy without introducing bias
    - Above, plus most other covariates
* Regression table, via stargazer
* Discussion of 5-10 omitted variables, for each: how it affects

## How to do:
* Use OLS regression
* Omitted variables will be a major obstacle
* Aim for causal estimates, clearly explaining how omitted variables may affect conclusions

## Reading the data

Let us first read the data.

```{r}
crime0 = read.csv("crime_v2.csv")
summary(crime0)
# There are 6 rows with NA's
crime0 <- crime0 %>% na.omit()
colnames(crime0)
# Commented for conciseness
# structure(crime0)

# prbconv is a factor: convert to float instead
# commented for conciseness
# levels(crime0$prbconv)
crime0$prbconv = as.numeric(levels(crime0$prbconv))[crime0$prbconv]

# FIXME: is it better to replace with NA instead of removing the data?
crime = crime0 %>% dplyr::select(-year)
# Commented for conciseness
# structure(crime)
```

Our dependent variable is going to be $crmrte$.  We want to come up with a model that can predict crime rate.

The following columns are interesting:

* county: county number
* prbarr: Probability of arrest (ratio: arrest/offense)
* prbconv: Probability of conviction (ratio: conviction/arrest)
* prbpris: Probability of prison sentence (ratio: prison/total convictions)
* avgsen: Average sentence in days
* polpc: Police per capita
* density: People per square mile
* taxpc: Tax revenue per capita
* west/central/urban: Geographical location
* pctmin80: % minority (1980)
* wcon/wtuc/wtrd/wfir/wser/wmfg/wfed/wsta/wloc: Weekly wages across sectors
* mix: Offense mix: face-to-face/other
* pctymle: % young male

Possible collinearity pairs we should check for:

* urban and density
* prbarr, prbconv, prbpris
* wages across sectors

Anything else?

Interesting causal questions:

* Can low probabilities of arrest, conviction, or sentence drive high crime rate?  Answer: Yes (for arrest)
* Can low sentencing period cause high crime rate?  Answer: No
* Can fewer police per capita cause high crime rate?
* Can very high or very low density cause crime?
* Can lower tax revenue cause crime?
* Can geographical location cause crime?
* Is crime higher in urban areas, certain counties?
* Can high % of young males drive crime?
* Can low wages cause crime?
* Can high numbers of minorities cause crime, esp hate crime?

### Utility functions

We will now define some utility functions to aid our EDA.

```{r}
f_check_null <- function(in_field_name) {
  sql <- sprintf("SELECT COUNT(1) as COUNT_NULL_OR_NA FROM crime WHERE (%s IS \"NA\" or %s IS NULL)", in_field_name, in_field_name)
  sqldf(sql)
}

f_plot_one <- function(in_db_field_name,in_main_title) {
  title_log <- paste("log of",in_main_title, sep = " ")
  par(mfrow=c(2,2))
  hist(in_db_field_name, main=in_main_title)
  hist(log(in_db_field_name), main=title_log)
  plot(in_db_field_name, main=in_main_title)
  boxplot(in_db_field_name, main=in_main_title)
}

f_plot_two <- function(in_field_name1,in_xlabel,in_field_name2,in_y_label, in_main_title ){
  

  theme_update(plot.title = element_text(hjust = 0.5))

  p1<-ggplot(crime1, aes_string(in_field_name1,in_field_name2)) + 
         geom_point() +
         geom_smooth(na.rm = FALSE, method = loess)
  p1 + ggtitle(in_main_title) +xlab(in_xlabel) + ylab(in_y_label)
}

f_plot_three  <- function(in_field_x,in_xlabel,in_field_y,in_y_label){

corr_val=round(cor(in_field_y, in_field_x),4)

main_title=paste(in_xlabel,'v/s',in_y_label, sep = ' ')
plot(in_field_x, in_field_y, 
     main = main_title,
      sub=paste("Corr. coefficient:",corr_val),
      xlab=in_xlabel, 
      ylab=in_y_label)
m = lm( in_field_y ~ in_field_x) 
abline(m)

}

```

# Exploratory Data Analysis

## Variables of interest

### Crime rate

Crime rate has a right skew with many outliers on the higher end.  We can use a log function to transform the distribution to be closer to normal.

```{r}
#f_check_null("crmrte")
f_plot_one(crime$crmrte,"crime rate")
# We can take logarithm to make the data more normally distributed
crime$logcrmrte=log(crime$crmrte)
```

### Probability of arrest, conviction, prison


```{r}
f_plot_one(crime$prbarr,"probability of arrest")
crime$logprbarr=log(crime$prbarr)
```

Probability of arrest has one large outlier, with a value above 1.0.  This significantly affects the distribution.

```{r}
crime %>% filter(prbarr > 1.0) %>% dplyr::select(everything())
```

Let us remove this data point and replot.  In a real-world scenario, this would need further investigation.

```{r}
crime <- crime %>% filter(prbarr <= 1.0)
f_plot_one(crime$prbarr,"probability of arrest")
```

We no longer need any transformation and we can use the data as-is.

```{r}
f_plot_one(crime$prbconv,"probability of conviction")
crime$logprbconv=log(crime$prbconv)
```

Probability of conviction has a few outliers, one with a value above 2.0.  This significantly affects the distribution.

```{r}
crime %>% filter(prbconv > 2.0) %>% dplyr::select(everything())
```

Let us remove this data point and replot.  In a real-world scenario, this would need further investigation.

```{r}
crime <- crime %>% filter(prbconv <= 1.0)
f_plot_one(crime$prbconv,"probability of conviction")
```

We no longer need any transformation and we can use the data as-is.

```{r}
f_plot_one(crime$prbpris,"probability of prison")
crime$logprbpris=log1p(crime$prbpris)
```

### Average sentence

```{r}
f_plot_one(crime$avgsen,"avg. sentence, days")
```

### Police per capita

```{r}
f_plot_one(crime$polpc,"police per capita")
```

### Density

```{r}
f_plot_one(crime$density,"density")
```

We can normalize density by taking a cube root:

```{r}
hist((crime$density)^(1/3))
crime$crdensity <- (crime$density)^(1/3)
```

### Tax revenue per capita

```{r}
f_plot_one(crime$taxpc,"tax revenue per capita")
hist(log1p(crime$taxpc))
crime$logtaxpc <- log1p(crime$taxpc)
```

Tax revenue has one outlier beyond 120:

```{r}
crime %>% filter(taxpc > 100) %>% dplyr::select(everything())
```

Let us remove it and replot.

```{r}
# crime <- crime %>% filter(taxpc <= 100)
f_plot_one(crime$taxpc,"tax revenue per capita")
```

### Minority percentage

```{r}
f_plot_one(crime$pctmin80,"minority pc")
```

The data shows considerable skew.

We can transform as follows:

```{r}
hist((crime$pctmin80)^(1/3))
crime$crpctmin80 = crime$pctmin80 ^ (1/3)
```

### Young male percentage

```{r}
f_plot_one(crime$pctymle,"minority pc")
```

The data shows considerable skew.  Let us apply a polynomial transform:

```{r}
hist(crime$pctymle^(1/3))
crime$crpctymle <- crime$pctymle^(1/3)
```

### Wages

```{r}
wages = c("wcon", "wfed", "wfir", "wloc", "wmfg", "wser", "wsta", "wtrd", "wtuc")
par(mfrow = c(3, 3))
for (col in wages) {
    hist(crime[,col], main=title(col))
}
```

```{r}
wages = c("wcon", "wfed", "wfir", "wloc", "wmfg", "wser", "wsta", "wtrd", "wtuc")
par(mfrow = c(3, 3))
for (col in wages) {
    boxplot(crime[,col], main=col)
}
```
Most of the wages are already normally distributed.  The following are exceptions:

```{r}
f_plot_one(crime$wtrd,"Wages: trading")
crime$logwtrd <- log(crime$wtrd)
```

```{r}
f_plot_one(crime$wfir,"Wages: fir")
crime$logwfir <- log(crime$wfir)
```

```{r}
f_plot_one(crime$wfir,"Wages: mfg")
crime$logwmfg <- log(crime$wmfg)
```

### Mix

```{r}
f_plot_one(crime$mix,"crime mix")
```

There is some skew.  Let us apply the log transform:

```{r}
crime$logmix <- log(crime$mix)
```


```{r}
#scatterplotMatrix(crime[,c("wcon", "wfed", "wfir", "wloc", "wmfg", "wser", "wsta", "wtrd", "wtuc")])
#hist(crime[,c("wcon", "wfed", "wfir", "wloc", "wmfg", "wser", "wsta", "wtrd", "wtuc")])
```

From the scatterplot, most of the wages have normal distribution.  

Let us fit an initial model.

```{r}
m = lm(logcrmrte ~ prbarr + prbconv + prbpris + avgsen + polpc + crdensity + logtaxpc + crpctmin80 + crpctymle + logmix + wcon + wfed + logwfir + wloc + logwmfg + wser + wsta + logwtrd + wtuc, data=crime)
summary(m)
```
The initial model shows the following variables as significant:

* Probability of arrest (prbarr)
* Police per capita (polpc)
* Density, transformed as cube root (crdensity)
* Percent minorities, transformed as cube root (crpctmin80)

```{r}
m = lm(logcrmrte ~ prbarr + polpc + crdensity + crpctmin80, data=crime)
summary(m)
par(mfrow=c(2,2))
plot(m)
```

This shows adjusted $R^2$ of 0.79, which is quite close to the fit of 0.86 we obtained by fitting all variables.

Cook's distance is high for record #23.  Let us look at it:
```{r}
crime %>% slice(23) %>% dplyr::select(everything())
```

If we consider this to be an outlier and remove it from the dataset, then we will have a modified model.

```{r}
crime2 <- crime %>% slice(-23)
m = lm(logcrmrte ~ prbarr + polpc + crdensity + crpctmin80, data=crime2)
summary(m)
par(mfrow=c(2,2))
plot(m)
```

The model will be:
$$\log{crmrte} = -5.15 -1.37\ prbarr + 275\ polpc + 0.781\ \sqrt[^3]{density} + 0.294\ \sqrt[^3]{pctmin80}$$
Next, we can add some more variables as follows:

* crpctymle
* logfir

```{r}
m = lm(logcrmrte ~ prbarr + polpc + crdensity + crpctmin80 + crpctymle + logwfir, data=crime2)
summary(m)
```

And even more:

* avgsen
* wfed
* wser
* wsta

```{r}
m = lm(logcrmrte ~ prbarr + polpc + crdensity + crpctmin80 + crpctymle + logwfir + avgsen + wfed + wser + wsta, data=crime2)
summary(m)
```

It is worth checking these variables for collinearity and to look for omitted variables.  Otherwise we risk overfitting our model.

```{r}
# Run variance inflation factor
vif(m)
# Run principal component analysis
pca <- prcomp(~ prbarr + polpc + crdensity + crpctmin80 + crpctymle + logwfir + avgsen + wfed + wser + wsta, data=crime2, center = TRUE, scale.=TRUE)
summary(pca)
plot(pca, type="l")
```

Variance inflation factors look OK: there are no values greater than 5.  PCA analysis shows that the first 3-4 components (prbarr, polpc, crdensity, crpctmin80) explain almost all of the variance.  The remaining factors are not very relevant.

```{r}
scatterplotMatrix(~ prbarr + polpc + crdensity + crpctmin80 + crpctymle + logwfir + avgsen + wfed + wser + wsta, data=crime2)
```

# Bivariate EDA

```{r}
cor(c(crime$wcon, crime$wfed, crime$wfir, crime$wloc, crime$wmfg, crime$wser, crime$wsta, crime$wtrd, crime$wtuc), crime$crmrte)
pairs(crmrte ~ wcon + wfed + wfir + wloc + wmfg + wser + wsta + wtrd + wtuc, data = crime)
```

## County and crime rate

Crime seems to be uniformly distributed across the counties.

```{r}
par(mfrow = c(1, 2))
hist(crime$county)
west_crime <- crime %>% filter(west == 1) %>% count()
central_crime <- crime %>% filter(central == 1) %>% count()
other_crime <- crime %>% filter(west == 0 & central == 0) %>% count()
barplot(c(west_crime$n, central_crime$n, other_crime$n), names.arg=c("Wst", "Ctr", "Oth"))
```

## Arrests and crime rate

We see arrests and conviction driving down crime rate:

```{r}
par(mfrow = c(1, 2))

plot(crime$prbarr, crime$crmrte, xlim=c(0,1.0))
m = lm(crime$crmrte ~ crime$prbarr)
abline(m)

plot(crime$prbconv, crime$crmrte, xlim=c(0,1.0))
m = lm(crime$crmrte ~ crime$prbconv)
abline(m)
```

Policy recommendation: enable infrastructure to allow for catching of criminals.

TODO: Check for multicollinearity in the arrest, conviction and prison rates.

## Prison sentence and crime rate

However, not much effect based on whether prison sentence happened and how long the sentence was.

```{r}
par(mfrow = c(1, 2))

plot(crime$prbpris, crime$crmrte)
m = lm(crime$crmrte ~ crime$prbpris)
abline(m)

plot(crime$avgsen, crime$crmrte)
m = lm(crime$crmrte ~ crime$avgsen)
abline(m)
```

Policy recommendation: Probability of prison sentence does not affect crime rate much; it is higher where average sentences are high.

## Police and crime rate

We see higher police per capita associated with higher crime rate.  This could be because we are deploying more police in higher crime areas (effect, not cause) or perhaps the additional police are not being effective enough in deterring crime.

```{r}
par(mfrow = c(1, 2))

plot(crime$polpc, crime$crmrte)
m = lm(crime$crmrte ~ crime$polpc)
abline(m)

plot(m, which=5)
```

The residuals graph shows that row 72 has a lot of leverage, but it still falls short of Cook's distance of 1.  So we will keep it as-is.  Let us look at the row though.  We can also drop the row and see how the graph changes.

```{r}
crime %>% slice(71) %>% select(everything())

par(mfrow = c(1, 2))

plot(crime$polpc, crime$crmrte, xlim=c(0,0.004))
m = lm(crime$crmrte ~ crime$polpc)
abline(m)

# TODO: Check what's special in rows 71, 5, 23
crime2 = crime %>% slice(-71) %>% slice(-5) %>% slice(-22)
plot(crime2$polpc, crime2$crmrte, xlim=c(0,0.004))
m = lm(crime2$crmrte ~ crime2$polpc)
abline(m)
```

The graph has a higher slope if we remove the outliers.

Policy recommendation: increase effectiveness of police.

## Density

Let us check if population density affects crime.

```{r}
plot(crime$density, crime$crmrte)
m = lm(crime$crmrte ~ crime$density)
abline(m)
```

It looks like crime rate goes up with density, although data is sparse at higher densities.

### Tax revenue

How does tax revenue per capita affect crime rate?

```{r}
plot(crime$taxpc, crime$crmrte)
m = lm(crime$crmrte ~ crime$taxpc)
abline(m)
```

We see that crime rate goes up as tax revenue per capita goes up.  This could be because higher tax revenue implies higher income and therefore higher chance for theft or burglary.

### Geographic location
```{r}
par(mfrow = c(1, 3))

crime_west = crime %>% filter(west == 1)
crime_central = crime %>% filter(central == 1)
crime_rest = crime %>% filter(west == 0 & central == 0)
boxplot(crime_west$crmrte, main="Crime: West", ylim=c(0,0.10))
boxplot(crime_central$crmrte, main="Crime: Central", ylim=c(0,0.10))
boxplot(crime_rest$crmrte, main="Crime: Rest", ylim=c(0,0.10))
```

Crime rate is higher in the central region, with one clear outlier (1 in 10).  But crime range is higher in the remaining regions.

### Urban vs rural

Is crime rate higher in urban or rural areas?

```{r}
par(mfrow = c(1, 2))

crime_urban = crime %>% filter(urban == 1)
crime_rural = crime %>% filter(urban == 0)
boxplot(crime_urban$crmrte, main="Crime: Urban", ylim=c(0,0.10))
boxplot(crime_rural$crmrte, main="Crime: Rural", ylim=c(0,0.10))
```

Clearly, crime rate is higher in urban areas.  We need to focus on urban areas.

### Minorities

```{r}
plot(crime$pctmin80, crime$crmrte)
m = lm(crime$crmrte ~ crime$pctmin80)
abline(m)
```

As minorities go up, we see a slight increase in crime rate.

### Offense mix

Let's see how mix affects crime rate.

```{r}
plot(crime$mix, crime$crmrte)
m = lm(crime$crmrte ~ crime$mix)
abline(m)
```

We see that high crime rates are correlated with low crime mix: i.e. these crimes do not involve face-to-face interaction.

### Young males

```{r}
par(mfrow = c(1, 2))

plot(crime$pctymle, crime$crmrte)
m = lm(crime$crmrte ~ crime$pctymle)
abline(m)

plot(m, which=5)
```

We see that crime rate goes up as we have higher percentage of young males.  Row 53 is an outlier with large Cook's distance.  Let us have a look at it.  This is county 133, which has 5.5% crime rate and 25% young male population.

```{r}
crime %>% slice(53) %>% select(everything())
```

Let us remove this data and try again:

```{r}
par(mfrow = c(1, 2))

plot(crime$pctymle, crime$crmrte, xlim=c(0,0.26))
m = lm(crime$crmrte ~ crime$pctymle)
abline(m)

crime_no53 = crime %>% slice(-53)
plot(crime_no53$pctymle, crime_no53$crmrte, xlim=c(0,0.26))
m = lm(crime_no53$crmrte ~ crime_no53$pctymle)
abline(m)
```

There is a marked increase in slope.  However, we have a wide band of crime rate in the 6-12% young male range.  Our $R^2$ is only 9%.

```{r}
summary(m)
```

## Wages and crime rate

As wage goes up, crime seems to go up.

```{r}
par(mfrow = c(3, 3))
m = lm(crime$crmrte ~ crime$wcon, data=crime)
plot(crime$wcon, crime$crmrte)
abline(m)

m = lm(crime$crmrte ~ crime$wfed, data=crime)
plot(crime$wfed, crime$crmrte)
abline(m)

m = lm(crime$crmrte ~ crime$wfir, data=crime)
plot(crime$wfir, crime$crmrte)
abline(m)

m = lm(crime$crmrte ~ crime$wloc, data=crime)
plot(crime$wloc, crime$crmrte)
abline(m)

m = lm(crime$crmrte ~ crime$wmfg, data=crime)
plot(crime$wmfg, crime$crmrte)
abline(m)

m = lm(crime$crmrte ~ crime$wser, data=crime)
plot(crime$wser, crime$crmrte)
abline(m)

m = lm(crime$crmrte ~ crime$wsta, data=crime)
plot(crime$wsta, crime$crmrte)
abline(m)

m = lm(crime$crmrte ~ crime$wtrd, data=crime)
plot(crime$wtrd, crime$crmrte)
abline(m)

m = lm(crime$crmrte ~ crime$wtuc, data=crime)
plot(crime$wtuc, crime$crmrte)
abline(m)
```

### Checking for collinearity

Let us look for pairs of variables with high correlation.

```{r}
# Build the matrix
crime_cor_matrix <- round(cor(crime), 2)
# It is symmetric
crime_cor_matrix[upper.tri(crime_cor_matrix, diag=TRUE)] <- NA
crime_cor_df <- as.data.frame(as.table(crime_cor_matrix))
# Select pairs with high correlation
crime_cor_df %>% 
  filter(abs(Freq) >= 0.66) %>% 
  arrange(desc(Freq)) %>% 
  select(everything()) 
```

We see that $urban$ and $density$ have high correlation, so we can use one instead of both.  There is also high correlation between wages in finance and investments $wfir$ vs. trade and retail $wtrd$.  We can keep one instead of the other.

### Selecting variables based on statistical significance

First, we will simply try to fit all the independent variables and then remove those that do not add a lot of statistical significance.

```{r}
# Source: https://www.youtube.com/watch?v=I4z3yjoEADY
m <- lm(crime$crmrte ~ ., crime)
summary(m)
```

The default model has an $R^2$ value of 0.85.

We see that the following variables are significant (p < 0.1):

* prbarr
* avgsen
* polpc
* density
* central
* pctmin80
* wser
* wsta
* pctymle

Let us try to build a newer model with the above (fewer) variables.

```{r}
m <- lm(crime$crmrte ~ prbarr + avgsen + polpc + 
          density + central + pctmin80 + wser + wsta + pctymle,
        crime)
cor(crime$pctymle, crime$crmrte)
summary(m)
```

Our $R^2$ is still 0.8, which is quite significant.

Let us analyze the independent variables for causality.

* prbarr: it is plausible that we have more arrests in areas with high crime (effect, not cause)
* avgsen: Same reasoning can hold for average sentence: high crime rate can result in higher average sentences
* polpc: It is possible that high number of police per capita is a result of high crime rate, not a cause
* density: Density sounds like a possible cause: higher population density means higher opportunity for anonymity and lower probability of detection
* central: Central NC has higher crime rate but this could be due to omitted variables such as higher density or urban population
* pctmin80: Higher percentage of minorities can indicate social tension and anonymity, causing higher crime rate.
* wser, wsta: Wages in services and state is not causal: it is probably due to omitted variables.  These wages are probably higher in urban areas due to higher minimum wage.
* pctymle: % young male is probably causal.  Young men are known to engage in risky, aggressive behavior that correlates well with crime rate.

So our causal variables can be:
* density
* pctmin80
* pctymle

Let us fit the model:

```{r}
m <- lm(crime$crmrte ~ density + pctmin80 + pctymle,
        crime)
summary(m)
plot(m)
```

The $R^2$ is still 0.6, which is quite high for only three predictors.

Possible policy suggestions:

* Are we arresting criminals?
* Are we convicting too much or too little?
* Should we increase police presence?
* Is higher tax revenue going to cut down on crime?
* How is crime spread across West, Central and urban NC?
* How is crime correlated with % minority?
* Are low wages driving crime?
* Is there hate crime in the area ("mix"), and is it correlated with % minority?
* How is crime connected to % young male?

