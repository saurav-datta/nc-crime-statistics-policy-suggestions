---
title: "Lab3 Draft, w203: Statistics for Data Science"
author: "Avinash Chandrasekaran"
date: "March 26, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, tidy.opts=list(width.cutoff=80), tidy=TRUE)
library(car)
library(corrplot)
library(lmtest)
library(sandwich)
library(stargazer)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(sqldf)
```

# 1. Introduction

Our team has been hired to provide research for a political campaign. The campaign has obtained a dataset of crime statistics for a selection of counties in North Carolina. Our task is to examine the data to help the campaign understand the determinants of crime and to generate policy suggestions that are applicable to local government.

The data provided consists of 25 variables and 91 different observations collected in a given year. Moreover the dataset obtained is a single cross-section of data collected from variety of different sources. For the analysis made in this research, we will assume that the data collected from different counties in NC were randomly sampled.

Our primary analysis of data will include ordinary least squares regressions to make casual estimates and we will clearly explain how omitted variabled may affect our conclusions. We begin our research by conducting exploratory analysis of the dataset to gain a better understanding of the variables.

# 2. Data Input

Let us read the data and have a first look.

```{r}
# Read the csv file
crime_data_raw = read.csv("crime_v2.csv")
```

### Empty rows

```{r include=FALSE}
summary(crime_data_raw)
tail(crime_data_raw, n=8)
```

There appears to be 6 rows of NA's across all variables. We can simply use na.omit(), because the number of all-NA rows matches the count on all the variables.

### Column formatting

We also notice that 'prbconv' is a factor while the rest of the variables are numeric.  West, central and urban are really categorical variables and not integers: we will treat them as such.

```{r}
# Remove NA rows
crime_data = na.omit(crime_data_raw)

# convert factor to numeric for variable prbconv
crime_data$prbconv = as.numeric(levels(crime_data$prbconv)[crime_data$prbconv])
# Convert some numerics into factors
crime_data$west = as.factor(crime_data$west)
crime_data$central = as.factor(crime_data$central)
crime_data$urban = as.factor(crime_data$urban)
```

### Unused variables

County and Year variables just represent the different counties and the year the data was collected. Year is always 87.  Hence, we can safely remove these from the dataset for further analysis.

```{r}
crime_data = crime_data %>% dplyr::select(-c(year, county))
```

### Duplicate records

We also noticed a duplicate record (record #89) in the dataset. As this could potentially affect our regression analysis, we will remove the duplicate record.

```{r}
duplicated(crime_data)[duplicated(crime_data)==TRUE]
crime_data = distinct(crime_data)
```

# 3. Exploratory Data Analysis

We will now try to get a sense of each variable in the dataset.

## Single variable analysis

```{r include=FALSE}
structure(crime_data)
```

There are a total of 90 observations across 23 different variables. We will now explore each of the variables collected in the data.

### Crime rate

```{r}
summary(crime_data$crmrte)
par(mfrow=c(1,2))
hist(crime_data$crmrte, main = "Crime rate", 
     xlab="Crime Rate")
hist(log(crime_data$crmrte), main = "Crime rate", 
     xlab="Log of Crime Rate")
```

The crime rate variable is the key dependent variable of interest. Looking at the histogram, the distribution is positively skewed to the left. We can take the log transformation which makes the variable appear more normally distributed.

Any skew in the original data may cause the residuals to not follow normal distribution.  If this happens, it violates an assumption of the LS regression model: we will not be able to draw inferences from our model.  Hence it is important to ensure our residuals to follow normal distribution as much as possible, and to transform our predictors if that helps.

Let us look at some predictor variables.

### Probability of arrest

```{r}
summary(crime_data$prbarr)
par(mfrow=c(2,2))
hist(crime_data$prbarr, main="Histogram")
boxplot(crime_data$prbarr, main="Box plot")
m = lm(crime_data$crmrte ~ crime_data$prbarr)
plot(crime_data$prbarr, crime_data$crmrte, main="Correlation with crime rate")
abline(m, col="blue")
cor(crime_data$crmrte, crime_data$prbarr)
```

The plot looks fairly normal, but there are 2 outliers.  It may seem odd that the value goes above 1.0 for a probability, but this is not a true probability: this is a ratio of arrests to offenses.  It may be that the convict escaped and a second arrest was made.  We will keep the values for now.

There is fairly strong negative correlation of -0.39: as probability of arrests increases, crime rate goes down.

### Probability of conviction

```{r}
hist(crime_data$prbconv, main="Histogram of Probability of convictions", 
     xlab="conviction probability")
summary(crime_data$prbconv)
```
The histogram plot doesn't look normal with more positive/left skew observed in the data. Moreover, plenty of values appear
above 1 which again seems odd considering this is a probability that is supposed to be between 0 and 1. 

Instead of excluding all values above 1, we likely have to assume these higher values denote high changes of getting
convicted in our analysis. From the definition of these terms provided, probability of arrest is proxied by the ratio of
of the arrests to offenses. And probability of conviction is proxied by ration of convictions to arrests, probability of 
prison sentence is proxied by convictions resulting in prison to total convictions. Since these are all "ratios" and not
true probabilities, we decided to not exclude and remove these values from the dataset.

Taking the log transformation of this statistics doesn't make much sense either. 

### Probability of prison sentence
```{r}
hist(crime_data$prbpris, main = "Histogram of Probability of prison sentence", 
     xlab="prison sentence prob")
```
This histogram plot looks fairly normal and we don't observe any weird values. 

### Average sentence days
```{r}
hist(crime_data$avgsen, main="Histogram of Average sentence in days", 
     xlab="avg sentence")
```
The average sentence in days looks slightly positive skewed. There appears to be an outlier with some values appearing
greater than 20 days. 

### Police per Capita
```{r}
par(mfrow=c(1,2))
hist(crime_data$polpc, main="Histogram of Police per capita", 
     xlab="police per capita")
hist(log(crime_data$polpc), main="Histogram of Police per capita", breaks=20,
     xlab="Log of police per capita")
summary(crime_data$polpc)
```
The histogram of police per capita appears to be postively skewed with some outlier on the far right closer to 0.01. Taking
the log of the metric makes the plot look more normal. The log transformation will likely be useful to examine the effects
of police presence on crime.

### People per sq. mile
```{r}
par(mfrow=c(1,2))
hist(crime_data$density, main="Histogram of density", 
     xlab="density")
hist(log(crime_data$density), main="Histogram of density", breaks=20,
     xlab="log density")
summary(crime_data$density)
crime_data = filter(crime_data, density>0.01)
```
The histogram of density shows lot of positive skew. The log transformation shows a more promising normal distribution
whereas it is skewed more towards the right due to a min value that seems out of place. We will continue to use the log
value but pay heed to the min value for anamolies.

We also observe one extreme outlier value of 0.000020342. This seems like an unlikely value for people per square mile
and we are thus removing it from consideration.


### Tax revenue per capita
```{r}
summary(crime_data$taxpc)
par(mfrow=c(1,2))
hist(crime_data$taxpc, main="Histogram of tax revenue per capita", breaks=20,
     xlab="tax review per capita")
hist(log(crime_data$taxpc), main="Histogram of tax revenue per capita", 
     breaks=20,
     xlab="Log of tax review per capita")
```
The tax revenue summary indicates a max value of 120, which might be a outlier assuming max of 100. The histogram is
sligtly positively skewed on the left and the log transformation appears to be normal yet still retaining small skew
towards the left

### Urban population
```{r}
sum(crime_data$urban == 1)
boxplot(crime_data$crmrte ~ crime_data$urban, ylab="Crime Rate",
        main="Crime Rate in rural vs. urban county",
        names=c("Rural", "Urban"))

```
There appears to be only 8 counties that are classified as urban in NC

When we compare the crime rates between rural and urban centers, it appears about 3 times higher in urban counties than rural counties. However there are only 8 data points for urban counties, so this might not be enough to devote serious consideration into this variable.

```{r}
boxplot(crime_data$density ~ crime_data$urban, ylab="Density",
        main="Density in Rural vs. Urban counties", 
        names=(c("Rural", "Urban")))
```
As expected the density of population is higher in urband couties as compared to rural counties.

### Percent minority
```{r}
hist(crime_data$pctmin80, main="Histogram of percent minority", breaks=20,
     xlab="percent of minority")
```
There doesn't seem to be anything odd about the percent of minority as calculated in 1980. Data and plot seems as expected. 
### Wage distribution
```{r}
par(mfrow=(c(3,3)))
hist(crime_data$wcon, breaks=20,
     main="Hist of wcon",ylab="Frequency", xlab="wagecon")
hist(crime_data$wtuc, breaks=20,
     main="Hist of wtuc",xlab="wagetuc", ylab="")
hist(crime_data$wloc, breaks=20,
     main="Hist of wloc",xlab="wageloc", ylab="")
hist(crime_data$wtrd, breaks=20,
     main="Hist of wtrd",ylab="Frequency", xlab="wagetrd")
hist(crime_data$wfir, breaks=20,
     main="Hist of wfir",xlab="wagefir", ylab="")
hist(crime_data$wser, breaks=20,
     main="Hist of wser",xlab="wageser", ylab="")
hist(crime_data$wmfg, breaks=20,
     main="Hist of wmfg",ylab="Frequency", xlab="wagemfg")
hist(crime_data$wfed, breaks=20,
     main="Hist of wfed",xlab="wagefed", ylab="")
hist(crime_data$wsta, breaks=20,
     main="Hist of wsta",xlab="wagesta", ylab="")

```
Most of the wage variables conform to normal distributions.
```{r}
summary(crime_data$wser)
crime_data= filter(crime_data, wser<2177)
```
Wage in service industry does seem to have one strange outlier that is causing some skewness in the plot.
We believe this is likely an error and are thus removing it from consideration.


### Offense Mix & Percent of young males
```{r}
par(mfrow=c(1,2))
hist(crime_data$mix, main="Histogram of offense mix",
     xlab="offense mix, f2f/other")
hist(log(crime_data$mix), main="Histogram of offense mix",
     xlab="Log of offense mix")
```
Log transformation of offense mix is more normal while the percent of young males has a heavy left positive skew regardless of the log transformation

```{r}
par(mfrow=c(1,2))
hist(crime_data$pctymle, main="Hist of percent of young males",
     xlab="pct young males")
hist(log(crime_data$pctymle), main="Histogram of percent of young males",
     xlab="Log of pct young males")
```

## Data Transformation
Based on the univariate analysis performed above, we can opt to take the following transformations of the variables to make better analysis and judgement calls:

Log transformation of the Crime Rate, Police per Capita, Density per sq. mile, Tax revenue per capita
And finally scaling the percent (percent young male) and probabilities (arrest, conviction and prison sentence) to be between 0-100
```{r}
crime_data$log_crmrte = log(crime_data$crmrte)
crime_data$log_density = log(crime_data$density)
crime_data$log_polpc = log(crime_data$polpc)
crime_data$log_taxpc = log(crime_data$taxpc)
crime_data$adj_pctymle = crime_data$pctymle *100
crime_data$adj_prbarr = crime_data$prbarr *100
crime_data$adj_prbconv = crime_data$prbconv *100
crime_data$adj_prbpris = crime_data$prbpris *100

```

A final sumary table of our dataset with all transformation and data cleansing performed is displayed below:
```{r mylatextable, results = "asis"}
stargazer(crime_data, title = "Descriptive Statistics", digits=1)
```

## Bi-variate Analysis

The correlation plot between the different variables is as follows:
```{r}
corrplot(cor(crime_data[,
                        c("log_crmrte", "adj_prbarr", "adj_prbconv", "adj_prbpris", "avgsen", 
                          "log_polpc", "log_density", "log_taxpc", "pctmin80", "mix", 
                          "adj_pctymle")]), type = "upper")
corrplot(cor(crime_data[,
                        c("log_crmrte", "wcon", "wtuc", "wtrd", "wfir", "wser", "wmfg", "wfed", 
                          "wsta", "wloc")]), type = "upper")
```
We can see that there is a high positive correlation between:

- log of crime rate vs. log of policy per capita, log of tax revenue per capita, log of density and percent young male

- log of crime rate vs. most of the wage variables


And there is a high negative correlation between:

- log of crime rate vs. probability of arrests and conviction


The positive correlation observed makes sense for the following reasons:

1) More densely populated regions tends to observe more crimes
2) More wealthy areas (more wages and taxes) tend to have more crimes
3) More crimes leads to more police presence in a particular county to monitor and reduce crime rate

The negative correlations can be further observed using:
```{r}
par(mfrow=c(1,2))
plot(crime_data$adj_prbarr, crime_data$log_crmrte,
     main="Probability of arrest", ylab="Log Crime rate", xlab="Prob on arrest")
abline(lm(crime_data$log_crmrte ~ crime_data$adj_prbarr))
plot(crime_data$adj_prbconv, crime_data$log_crmrte,
     main="Probability of conviction vs. crime rate", ylab="Log Crime rate", 
     xlab="Prob on conv")
abline(lm(crime_data$log_crmrte ~ crime_data$adj_prbconv))
```
As seen above, as the probability of arrests and conviction go down, there are more criminals on the loose which leads to higher crime rates observed

### TODO: Talk about other possible correlations here?

### TODO: Discuss other interesting bi-variate analysis?

# 3. Model Specification and Assumptions

In our earlier analysis, we observed some key relationships between crime rate and other variables presented. Some of these variables had high positive correlation to crime rate while some others exhibited strong negative correlation.

For our first simple model, we will choose a subset of these variables that we believe are most important determinants of crime rate.

## Model 1
$$ log(Crime Rate) = \beta_0 + \beta_1 log(Density) + \beta_2(YoungMale) + \beta_3(Minority) + u$$
It is common knowledge that areas with higher density have more crime. Therefore we include that factor in our model.
Similarly we hypothesized that crime rate is high among minority and young male population, so we round off our model with
that factored in as well.

```{r}
model1 = lm(log(crmrte) ~ (log_density)+pctymle+pctmin80, data=crime_data)
model1$coefficients
par(mfrow=c(2,2))
plot(model1)
AIC(model1)
summary(model1)$r.squared
summary(model1)$adj.r.squared
```

## Model 2
high probability of arrests and conviction act as deterrents to crime.

$$ log(Crime Rate) = \beta_0 + \beta_1 log(Density) + \beta_2 (YoungMale) + \beta_3(Minority) + \beta_4(Conviction) + \beta_5 (Arrest) + \beta_6 (Tax) + u$$
```{r}
model2 = lm(log(crmrte) ~ (log_density)+pctymle+pctmin80+adj_prbarr+
            adj_prbconv+taxpc, data=crime_data)
model2$coefficients
par(mfrow=c(2,2))
plot(model2)
AIC(model2)
summary(model2)$r.squared
```

## Model 3
everything

```{r}
model3 = lm(log(crmrte) ~ (log_density)+pctymle+pctmin80+adj_prbarr+adj_prbconv+
              taxpc+log_polpc, data=crime_data)
model3$coefficients
par(mfrow=c(2,2))
plot(model3)
AIC(model3)
summary(model3)$r.squared
```

```{r results = "asis"}
stargazer(model1, model2, model3)
```
# 5. Discussion of omitted variables (Identify what you think are the 5-10 most important omitted variables that bias results you care about.)

Education

Unemployment

Poverty


```{r}

```